{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping refers to the process of automatically extracting data from websites. It involves using software or tools to gather information from web pages, parse the HTML content, and extract specific data elements, such as text, images, tables, and more. Web scraping is commonly used to gather data from multiple web pages quickly and efficiently, without the need for manual data entry.\n",
    "\n",
    "Web scrapping is used for :- \n",
    "1. Data Collection and Analysis\n",
    "2. Real estate and travel information\n",
    "3. Finance extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different methods used for web scrapping are :- \n",
    "1. Manual copying and pasting\n",
    "2. Web Scrapping framework\n",
    "3. API\n",
    "4. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. It provides a convenient way to navigate, search, and manipulate the elements within these documents. Beautiful Soup is commonly used for web scraping tasks to extract specific data from web pages by traversing the HTML structure and accessing elements like tags, attributes, and text content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask is a lightweight and flexible web framework in Python. It might be used in a web scraping project to create a user interface for interacting with the scraping functionality, displaying scraped data, and providing user input options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Amazon EC2 :- provides virtual servers in the cloud\n",
    "2. Amazon S3 :-  S3 is an object storage service. You could use it to store the scraped data, images, or any other files generated during the web scraping process.\n",
    "3. Amazon lambda :- AWS Lambda allows you to run code without provisioning or managing servers.\n",
    "4. Amazon RDS (Relational Database Service):- If your project requires storing structured data, RDS can host a relational database like MySQL, PostgreSQL, etc., to store and manage the scraped information in a structured manner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
